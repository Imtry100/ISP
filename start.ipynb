{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20be7367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WhisperX model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint d:\\Yoshi Studio\\Reels\\Reels\\Lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      ">>Performing voice activity detection using Pyannote...\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.7.1+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Processing: videoplayback.mp4...\n",
      "Failed to process videoplayback.mp4: [WinError 2] The system cannot find the file specified\n",
      "All tasks finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisperx\n",
    "import torch\n",
    "\n",
    "# --- Configuration ---\n",
    "SOURCE_PATH = r\"D:\\IS Project\\video\\videoplayback.mp4\"  # Can be a single file or a folder\n",
    "OUTPUT_FOLDER = r\"D:\\IS Project\\transcripts\"  # Folder where text files will be saved\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "BATCH_SIZE = 4  # Reduce if you run out of GPU memory\n",
    "COMPUTE_TYPE = \"float16\" if torch.cuda.is_available() else \"int8\"  # \"float16\" for GPU, \"int8\" for CPU\n",
    "\n",
    "def transcribe_videos():\n",
    "    # 1. Create output folder if it doesn't exist\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "    # 2. Load the WhisperX model\n",
    "    print(\"Loading WhisperX model...\")\n",
    "    try:\n",
    "        model = whisperx.load_model(\"large-v2\", device=DEVICE, compute_type=COMPUTE_TYPE)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # 3. Build list of video files to process\n",
    "    video_extensions = ('.mp4', '.mkv', '.mov', '.avi', '.webm')\n",
    "    \n",
    "    if os.path.isfile(SOURCE_PATH):\n",
    "        # Single file provided\n",
    "        video_files = [SOURCE_PATH] if SOURCE_PATH.lower().endswith(video_extensions) else []\n",
    "    elif os.path.isdir(SOURCE_PATH):\n",
    "        # Directory provided\n",
    "        video_files = [\n",
    "            os.path.join(SOURCE_PATH, f)\n",
    "            for f in os.listdir(SOURCE_PATH)\n",
    "            if f.lower().endswith(video_extensions)\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Source path does not exist: {SOURCE_PATH}\")\n",
    "        return\n",
    "\n",
    "    if not video_files:\n",
    "        print(\"No video files found.\")\n",
    "        return\n",
    "\n",
    "    for video_path in video_files:\n",
    "        filename = os.path.basename(video_path)\n",
    "        output_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, output_filename)\n",
    "\n",
    "        print(f\"Processing: {filename}...\")\n",
    "\n",
    "        try:\n",
    "            # 4. Load Audio directly from video (WhisperX uses ffmpeg internally)\n",
    "            audio = whisperx.load_audio(video_path)\n",
    "\n",
    "            # 5. Transcribe with VAD (Voice Activity Detection) to handle gaps\n",
    "            result = model.transcribe(audio, batch_size=BATCH_SIZE)\n",
    "\n",
    "            # 6. Save text to file\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                for segment in result[\"segments\"]:\n",
    "                    # Write text with a newline for each segment\n",
    "                    f.write(segment[\"text\"].strip() + \"\\n\")\n",
    "            \n",
    "            print(f\"Saved transcription to: {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    print(\"All tasks finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transcribe_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16904b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
