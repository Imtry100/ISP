{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be7367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WhisperX model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashf\\ISP\\isp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\yashf\\ISP\\isp\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\yashf\\ISP\\isp\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-09 17:49:03 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n",
      "2026-02-09 17:49:03 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\inspect.py:1007: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.6.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\yashf\\ISP\\isp\\Lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n",
      "c:\\Users\\yashf\\ISP\\isp\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cpu. Bad things might happen unless you revert torch to 1.x.\n",
      "Processing: videoplayback.mp4...\n",
      "Failed to process videoplayback.mp4: [WinError 2] The system cannot find the file specified\n",
      "All tasks finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import functools\n",
    "\n",
    "# Ensure ffmpeg is on PATH (freshly installed via winget)\n",
    "_ffmpeg_dir = r\"C:\\Users\\yashf\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-8.0.1-full_build\\bin\"\n",
    "if _ffmpeg_dir not in os.environ.get(\"PATH\", \"\"):\n",
    "    os.environ[\"PATH\"] = _ffmpeg_dir + \";\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "# Fix for PyTorch 2.6+ weights_only default change with pyannote/whisperx\n",
    "_original_load = torch.load\n",
    "\n",
    "@functools.wraps(_original_load)\n",
    "def _safe_load(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return _original_load(*args, **kwargs)\n",
    "\n",
    "torch.load = _safe_load\n",
    "\n",
    "import whisperx\n",
    "\n",
    "# --- Configuration ---\n",
    "SOURCE_PATH = r\"C:\\Users\\yashf\\ISP\\video\\videoplayback.mp4\"  # Can be a single file or a folder\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\yashf\\ISP\\transcripts\"  # Folder where text files will be saved\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "BATCH_SIZE = 4  # Reduce if you run out of GPU memory\n",
    "COMPUTE_TYPE = \"float16\" if torch.cuda.is_available() else \"int8\"  # \"float16\" for GPU, \"int8\" for CPU\n",
    "\n",
    "def transcribe_videos():\n",
    "    # 1. Create output folder if it doesn't exist\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "    # 2. Load the WhisperX model\n",
    "    print(\"Loading WhisperX model...\")\n",
    "    try:\n",
    "        model = whisperx.load_model(\"large-v2\", device=DEVICE, compute_type=COMPUTE_TYPE)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # 3. Build list of video files to process\n",
    "    video_extensions = ('.mp4', '.mkv', '.mov', '.avi', '.webm')\n",
    "    \n",
    "    if os.path.isfile(SOURCE_PATH):\n",
    "        # Single file provided\n",
    "        video_files = [SOURCE_PATH] if SOURCE_PATH.lower().endswith(video_extensions) else []\n",
    "    elif os.path.isdir(SOURCE_PATH):\n",
    "        # Directory provided\n",
    "        video_files = [\n",
    "            os.path.join(SOURCE_PATH, f)\n",
    "            for f in os.listdir(SOURCE_PATH)\n",
    "            if f.lower().endswith(video_extensions)\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Source path does not exist: {SOURCE_PATH}\")\n",
    "        return\n",
    "\n",
    "    if not video_files:\n",
    "        print(\"No video files found.\")\n",
    "        return\n",
    "\n",
    "    for video_path in video_files:\n",
    "        filename = os.path.basename(video_path)\n",
    "        output_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, output_filename)\n",
    "\n",
    "        print(f\"Processing: {filename}...\")\n",
    "\n",
    "        try:\n",
    "            # 4. Load Audio directly from video (WhisperX uses ffmpeg internally)\n",
    "            audio = whisperx.load_audio(video_path)\n",
    "\n",
    "            # 5. Transcribe with VAD (Voice Activity Detection) to handle gaps\n",
    "            result = model.transcribe(audio, batch_size=BATCH_SIZE)\n",
    "\n",
    "            # 6. Save text to file\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                for segment in result[\"segments\"]:\n",
    "                    # Write text with a newline for each segment\n",
    "                    f.write(segment[\"text\"].strip() + \"\\n\")\n",
    "            \n",
    "            print(f\"Saved transcription to: {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    print(\"All tasks finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transcribe_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16904b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
